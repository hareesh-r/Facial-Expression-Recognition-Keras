{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(\"face.xml\") #xml file for OpenCV to detect frontal face\n",
    "model = load_model(\"checkpoint1.h5\") #out pretrained weighted file \n",
    "\n",
    "class_labels = [\"Angry/Disgiust\",\"Happy\",\"Neutral\",\"Sad\",\"Surprise/Fear\"]\n",
    "\n",
    "cap = cv2.VideoCapture( r\"E:\\ML\\FACE EXPRESSIOON\\exp.mp4\" ) #your video file here (\"0\" in case of webcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        ret , frame = cap.read() #return valur and the fram\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        #converting to gray as our data was trained using gray images\n",
    "        \n",
    "        faces = face_classifier.detectMultiScale( gray , scaleFactor=1.3 , minNeighbors = 5 )\n",
    "\n",
    "        for x,y,w,h in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,225,225),3) #drawing the rectangle over faces\n",
    "\n",
    "            roi_gray = gray[y:y+h,x:x+w] #again converting the rectangle portion to gray to make sure\n",
    "            roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA ) #resizing as per our dataset 48*48\n",
    "\n",
    "            if np.sum([roi_gray])!=0:\n",
    "                roi = roi_gray.astype(\"float\")/255.0\n",
    "                roi = img_to_array(roi)\n",
    "                roi = np.expand_dims(roi,axis=0)\n",
    "\n",
    "                pred = model.predict(roi)[0]\n",
    "                labels = class_labels[pred.argmax()]\n",
    "                # gets the label from our array\n",
    "                label_position=(x,y)\n",
    "                #starting of our rectangle\n",
    "                cv2.putText(frame,labels,label_position,cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,2,(0,225,0),3)\n",
    "                #places the text\n",
    "            else:\n",
    "                cv2.putText(frame,\"No Face Found Sorry!\",(20,60),cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,2,\"red\",3)\n",
    "                \n",
    "        cv2.namedWindow('Facial Expression Recognition',cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('Facial Expression Recognition', 1000,800)\n",
    "        cv2.imshow(\"Facial Expression Recognition\",frame)\n",
    "        #showing the final rendered video\n",
    "        if cv2.waitKey(1) & 0xFF==ord(\"q\"): #if \"Q\" is pressed then the video window will be closed\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    #closes the frame window\n",
    "except:\n",
    "    print(\"error occured\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
